"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[924],{8453:(e,n,r)=>{r.d(n,{R:()=>a,x:()=>i});var t=r(6540);const s={},o=t.createContext(s);function a(e){const n=t.useContext(o);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),t.createElement(o.Provider,{value:n},e.children)}},9712:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>d,frontMatter:()=>a,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"appendices/appendix-e-code-templates","title":"Appendix E: Code Templates","description":"This appendix provides reusable code templates for common tasks in Physical AI and Humanoid Robotics development using ROS 2, Gazebo, and NVIDIA Isaac.","source":"@site/docs/appendices/appendix-e-code-templates.md","sourceDirName":"appendices","slug":"/appendices/appendix-e-code-templates","permalink":"/physical-ai-textbook/appendices/appendix-e-code-templates","draft":false,"unlisted":false,"editUrl":"https://github.com/IlsaFatima1/physical-ai-textbook/tree/main/docs/appendices/appendix-e-code-templates.md","tags":[],"version":"current","frontMatter":{},"sidebar":"textbookSidebar","previous":{"title":"Appendix C: Troubleshooting Guide","permalink":"/physical-ai-textbook/appendices/appendix-c-troubleshooting"},"next":{"title":"Appendix G: Instructor Resources","permalink":"/physical-ai-textbook/appendices/appendix-g-resources"}}');var s=r(4848),o=r(8453);const a={},i="Appendix E: Code Templates",l={},c=[{value:"Basic ROS 2 Node Template",id:"basic-ros-2-node-template",level:2},{value:"Robot Control Node Template",id:"robot-control-node-template",level:2},{value:"Perception Node Template",id:"perception-node-template",level:2},{value:"Gazebo Integration Template",id:"gazebo-integration-template",level:2},{value:"Isaac Integration Template",id:"isaac-integration-template",level:2},{value:"Launch File Template",id:"launch-file-template",level:2},{value:"CMakeLists.txt Template",id:"cmakeliststxt-template",level:2},{value:"package.xml Template",id:"packagexml-template",level:2},{value:"Unit Test Template",id:"unit-test-template",level:2}];function p(e){const n={code:"code",h1:"h1",h2:"h2",header:"header",p:"p",pre:"pre",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"appendix-e-code-templates",children:"Appendix E: Code Templates"})}),"\n",(0,s.jsx)(n.p,{children:"This appendix provides reusable code templates for common tasks in Physical AI and Humanoid Robotics development using ROS 2, Gazebo, and NVIDIA Isaac."}),"\n",(0,s.jsx)(n.h2,{id:"basic-ros-2-node-template",children:"Basic ROS 2 Node Template"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\r\n"""\r\nTemplate for a basic ROS 2 node\r\n"""\r\n\r\nimport rclpy\r\nfrom rclpy.node import Node\r\nfrom std_msgs.msg import String\r\nfrom sensor_msgs.msg import JointState\r\nfrom geometry_msgs.msg import Twist\r\n\r\n\r\nclass BasicRobotNode(Node):\r\n    def __init__(self):\r\n        super().__init__(\'basic_robot_node\')\r\n\r\n        # Create publishers\r\n        self.publisher = self.create_publisher(String, \'robot_status\', 10)\r\n\r\n        # Create subscribers\r\n        self.joint_sub = self.create_subscription(\r\n            JointState,\r\n            \'joint_states\',\r\n            self.joint_callback,\r\n            10\r\n        )\r\n\r\n        # Create timer for periodic tasks\r\n        self.timer = self.create_timer(0.1, self.timer_callback)\r\n\r\n        # Internal state\r\n        self.joint_positions = []\r\n\r\n        self.get_logger().info(\'Basic robot node initialized\')\r\n\r\n    def joint_callback(self, msg):\r\n        """Process joint state messages"""\r\n        self.joint_positions = list(msg.position)\r\n        self.get_logger().debug(f\'Received {len(self.joint_positions)} joint positions\')\r\n\r\n    def timer_callback(self):\r\n        """Execute periodic tasks"""\r\n        # Publish status message\r\n        msg = String()\r\n        msg.data = f\'Node active with {len(self.joint_positions)} joints\'\r\n        self.publisher.publish(msg)\r\n\r\n    def cleanup(self):\r\n        """Cleanup function called on shutdown"""\r\n        self.get_logger().info(\'Node shutting down\')\r\n\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    node = BasicRobotNode()\r\n\r\n    try:\r\n        rclpy.spin(node)\r\n    except KeyboardInterrupt:\r\n        node.get_logger().info(\'Interrupted by user\')\r\n    finally:\r\n        node.cleanup()\r\n        node.destroy_node()\r\n        rclpy.shutdown()\r\n\r\n\r\nif __name__ == \'__main__\':\r\n    main()\n'})}),"\n",(0,s.jsx)(n.h2,{id:"robot-control-node-template",children:"Robot Control Node Template"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\r\n"""\r\nTemplate for robot control node with safety features\r\n"""\r\n\r\nimport rclpy\r\nfrom rclpy.node import Node\r\nfrom sensor_msgs.msg import JointState, Imu\r\nfrom geometry_msgs.msg import Twist\r\nfrom std_msgs.msg import Bool, Float64MultiArray\r\nimport numpy as np\r\nfrom typing import List, Optional\r\n\r\n\r\nclass RobotControlNode(Node):\r\n    def __init__(self):\r\n        super().__init__(\'robot_control\')\r\n\r\n        # Publishers\r\n        self.joint_cmd_pub = self.create_publisher(JointState, \'joint_commands\', 10)\r\n        self.cmd_vel_pub = self.create_publisher(Twist, \'cmd_vel\', 10)\r\n        self.emergency_pub = self.create_publisher(Bool, \'emergency_stop\', 10)\r\n\r\n        # Subscribers\r\n        self.joint_state_sub = self.create_subscription(\r\n            JointState, \'joint_states\', self.joint_state_callback, 10)\r\n        self.imu_sub = self.create_subscription(\r\n            Imu, \'imu/data\', self.imu_callback, 10)\r\n\r\n        # Control timer\r\n        self.control_timer = self.create_timer(0.01, self.control_loop)  # 100 Hz\r\n\r\n        # Internal state\r\n        self.current_joints = JointState()\r\n        self.current_imu = None\r\n        self.desired_velocities = np.zeros(20)  # 20 joints example\r\n        self.emergency_stop = False\r\n        self.safety_limits = {\r\n            \'max_velocity\': 2.0,  # rad/s\r\n            \'max_torque\': 100.0,  # Nm\r\n            \'max_acceleration\': 5.0  # rad/s\xb2\r\n        }\r\n\r\n        self.get_logger().info(\'Robot control node initialized\')\r\n\r\n    def joint_state_callback(self, msg: JointState):\r\n        """Update current joint state"""\r\n        self.current_joints = msg\r\n\r\n    def imu_callback(self, msg: Imu):\r\n        """Update IMU data for balance control"""\r\n        self.current_imu = msg\r\n\r\n    def control_loop(self):\r\n        """Main control loop with safety checks"""\r\n        if self.emergency_stop:\r\n            self.publish_emergency_stop()\r\n            return\r\n\r\n        # Perform safety checks\r\n        if not self.safety_check():\r\n            self.emergency_stop = True\r\n            self.publish_emergency_stop()\r\n            return\r\n\r\n        # Calculate desired joint commands\r\n        joint_commands = self.calculate_joint_commands()\r\n\r\n        # Publish commands\r\n        self.publish_joint_commands(joint_commands)\r\n\r\n    def safety_check(self) -> bool:\r\n        """Perform safety checks before executing commands"""\r\n        # Check for dangerous joint positions\r\n        if self.current_joints.position:\r\n            for pos in self.current_joints.position:\r\n                if abs(pos) > 3.14:  # Check for joint limits\r\n                    self.get_logger().error(\'Joint position limit exceeded\')\r\n                    return False\r\n\r\n        # Check for dangerous IMU readings (if available)\r\n        if self.current_imu:\r\n            # Check for excessive angular velocity\r\n            ang_vel = np.sqrt(\r\n                self.current_imu.angular_velocity.x**2 +\r\n                self.current_imu.angular_velocity.y**2 +\r\n                self.current_imu.angular_velocity.z**2\r\n            )\r\n            if ang_vel > 10.0:  # rad/s threshold\r\n                self.get_logger().error(\'Excessive angular velocity detected\')\r\n                return False\r\n\r\n        return True\r\n\r\n    def calculate_joint_commands(self) -> JointState:\r\n        """Calculate desired joint commands based on control logic"""\r\n        cmd = JointState()\r\n        cmd.header.stamp = self.get_clock().now().to_msg()\r\n        cmd.name = self.current_joints.name if self.current_joints.name else [f\'joint_{i}\' for i in range(20)]\r\n\r\n        # Example: simple position control\r\n        if self.current_joints.position:\r\n            cmd.position = [pos + 0.01 for pos in self.current_joints.position[:20]]\r\n        else:\r\n            cmd.position = [0.0] * 20\r\n\r\n        cmd.velocity = self.desired_velocities.tolist()\r\n        cmd.effort = [0.0] * len(cmd.position)\r\n\r\n        return cmd\r\n\r\n    def publish_joint_commands(self, joint_cmd: JointState):\r\n        """Publish joint commands with safety limits"""\r\n        # Apply safety limits\r\n        for i in range(len(joint_cmd.velocity)):\r\n            joint_cmd.velocity[i] = np.clip(\r\n                joint_cmd.velocity[i],\r\n                -self.safety_limits[\'max_velocity\'],\r\n                self.safety_limits[\'max_velocity\']\r\n            )\r\n\r\n        self.joint_cmd_pub.publish(joint_cmd)\r\n\r\n    def publish_emergency_stop(self):\r\n        """Publish emergency stop command"""\r\n        msg = Bool()\r\n        msg.data = True\r\n        self.emergency_pub.publish(msg)\r\n\r\n        # Stop all motion\r\n        stop_cmd = Twist()\r\n        self.cmd_vel_pub.publish(stop_cmd)\r\n\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    node = RobotControlNode()\r\n\r\n    try:\r\n        rclpy.spin(node)\r\n    except KeyboardInterrupt:\r\n        node.get_logger().info(\'Control node interrupted\')\r\n    finally:\r\n        node.destroy_node()\r\n        rclpy.shutdown()\r\n\r\n\r\nif __name__ == \'__main__\':\r\n    main()\n'})}),"\n",(0,s.jsx)(n.h2,{id:"perception-node-template",children:"Perception Node Template"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\r\n"""\r\nTemplate for perception node with image processing\r\n"""\r\n\r\nimport rclpy\r\nfrom rclpy.node import Node\r\nfrom sensor_msgs.msg import Image, CameraInfo\r\nfrom std_msgs.msg import Header\r\nfrom geometry_msgs.msg import Point\r\nimport numpy as np\r\nimport cv2\r\nfrom cv_bridge import CvBridge\r\nfrom typing import List, Tuple, Optional\r\n\r\n\r\nclass PerceptionNode(Node):\r\n    def __init__(self):\r\n        super().__init__(\'perception_node\')\r\n\r\n        # Publishers\r\n        self.detection_pub = self.create_publisher(Point, \'object_position\', 10)\r\n\r\n        # Subscribers\r\n        self.image_sub = self.create_subscription(\r\n            Image, \'camera/image_raw\', self.image_callback, 10)\r\n        self.camera_info_sub = self.create_subscription(\r\n            CameraInfo, \'camera/camera_info\', self.camera_info_callback, 10)\r\n\r\n        # Initialize tools\r\n        self.bridge = CvBridge()\r\n        self.camera_matrix = None\r\n        self.distortion_coeffs = None\r\n\r\n        # Processing parameters\r\n        self.object_detector = self.initialize_object_detector()\r\n\r\n        self.get_logger().info(\'Perception node initialized\')\r\n\r\n    def camera_info_callback(self, msg: CameraInfo):\r\n        """Update camera calibration parameters"""\r\n        if not self.camera_matrix:\r\n            self.camera_matrix = np.array(msg.k).reshape(3, 3)\r\n            self.distortion_coeffs = np.array(msg.d)\r\n            self.get_logger().info(\'Camera calibration updated\')\r\n\r\n    def image_callback(self, msg: Image):\r\n        """Process incoming camera images"""\r\n        try:\r\n            # Convert ROS image to OpenCV format\r\n            cv_image = self.bridge.imgmsg_to_cv2(msg, "bgr8")\r\n\r\n            # Process the image\r\n            detections = self.process_image(cv_image, msg.header)\r\n\r\n            # Publish results\r\n            if detections:\r\n                for detection in detections:\r\n                    self.detection_pub.publish(detection)\r\n\r\n        except Exception as e:\r\n            self.get_logger().error(f\'Error processing image: {e}\')\r\n\r\n    def process_image(self, cv_image: np.ndarray, header: Header) -> List[Point]:\r\n        """Process image to detect objects and return positions"""\r\n        detections = []\r\n\r\n        # Convert to HSV for color-based detection\r\n        hsv = cv2.cvtColor(cv_image, cv2.COLOR_BGR2HSV)\r\n\r\n        # Define color ranges for object detection\r\n        color_ranges = [\r\n            (np.array([0, 50, 50]), np.array([10, 255, 255])),  # Red\r\n            (np.array([100, 50, 50]), np.array([130, 255, 255]))  # Blue\r\n        ]\r\n\r\n        for lower, upper in color_ranges:\r\n            mask = cv2.inRange(hsv, lower, upper)\r\n            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\r\n\r\n            for contour in contours:\r\n                area = cv2.contourArea(contour)\r\n                if area > 1000:  # Filter small contours\r\n                    # Calculate centroid\r\n                    M = cv2.moments(contour)\r\n                    if M["m00"] != 0:\r\n                        cx = int(M["m10"] / M["m00"])\r\n                        cy = int(M["m01"] / M["m00"])\r\n\r\n                        # Create Point message with pixel coordinates\r\n                        point = Point()\r\n                        point.x = float(cx)\r\n                        point.y = float(cy)\r\n                        point.z = 0.0  # Will be updated with depth later\r\n\r\n                        detections.append(point)\r\n\r\n        return detections\r\n\r\n    def initialize_object_detector(self):\r\n        """Initialize object detection components"""\r\n        # This could be a deep learning model in practice\r\n        return {\r\n            \'min_area\': 1000,\r\n            \'confidence_threshold\': 0.7\r\n        }\r\n\r\n    def pixel_to_3d(self, pixel_x: float, pixel_y: float, depth: float) -> Tuple[float, float, float]:\r\n        """Convert pixel coordinates to 3D world coordinates"""\r\n        if self.camera_matrix is not None:\r\n            # Simple conversion using camera parameters\r\n            fx = self.camera_matrix[0, 0]\r\n            fy = self.camera_matrix[1, 1]\r\n            cx = self.camera_matrix[0, 2]\r\n            cy = self.camera_matrix[1, 2]\r\n\r\n            x = (pixel_x - cx) * depth / fx\r\n            y = (pixel_y - cy) * depth / fy\r\n\r\n            return x, y, depth\r\n\r\n        return pixel_x, pixel_y, depth  # Return pixel coordinates if no calibration\r\n\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    node = PerceptionNode()\r\n\r\n    try:\r\n        rclpy.spin(node)\r\n    except KeyboardInterrupt:\r\n        node.get_logger().info(\'Perception node interrupted\')\r\n    finally:\r\n        node.destroy_node()\r\n        rclpy.shutdown()\r\n\r\n\r\nif __name__ == \'__main__\':\r\n    main()\n'})}),"\n",(0,s.jsx)(n.h2,{id:"gazebo-integration-template",children:"Gazebo Integration Template"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\r\n"""\r\nTemplate for Gazebo integration with ROS 2\r\n"""\r\n\r\nimport rclpy\r\nfrom rclpy.node import Node\r\nfrom gazebo_msgs.srv import SetEntityState, GetEntityState\r\nfrom gazebo_msgs.msg import ModelState\r\nfrom geometry_msgs.msg import Pose, Twist\r\nfrom std_msgs.msg import Header\r\nimport time\r\n\r\n\r\nclass GazeboIntegrationNode(Node):\r\n    def __init__(self):\r\n        super().__init__(\'gazebo_integration\')\r\n\r\n        # Create service clients for Gazebo\r\n        self.set_state_client = self.create_client(\r\n            SetEntityState, \'/world/default/set_entity_state\')\r\n        self.get_state_client = self.create_client(\r\n            GetEntityState, \'/world/default/get_entity_state\')\r\n\r\n        # Wait for Gazebo services to be available\r\n        while not self.set_state_client.wait_for_service(timeout_sec=1.0):\r\n            self.get_logger().info(\'Waiting for set_entity_state service...\')\r\n\r\n        while not self.get_state_client.wait_for_service(timeout_sec=1.0):\r\n            self.get_logger().info(\'Waiting for get_entity_state service...\')\r\n\r\n        # Timer for periodic state updates\r\n        self.state_timer = self.create_timer(0.1, self.update_robot_state)\r\n\r\n        # Robot state\r\n        self.robot_name = \'my_robot\'\r\n        self.current_pose = Pose()\r\n        self.current_twist = Twist()\r\n\r\n        self.get_logger().info(\'Gazebo integration node initialized\')\r\n\r\n    def update_robot_state(self):\r\n        """Update robot state in Gazebo simulation"""\r\n        # Get current state\r\n        future = self.get_state_client.call_async(\r\n            self.create_get_state_request(self.robot_name, \'world\')\r\n        )\r\n\r\n        # Process the response (in a real implementation, you\'d handle the future properly)\r\n        # For now, just log that we\'re updating state\r\n        self.get_logger().debug(f\'Updating state for {self.robot_name}\')\r\n\r\n    def create_set_state_request(self, entity_name: str, pose: Pose, twist: Twist):\r\n        """Create a SetEntityState request"""\r\n        from gazebo_msgs.srv import SetEntityState\r\n\r\n        req = SetEntityState.Request()\r\n        req.state.name = entity_name\r\n        req.state.pose = pose\r\n        req.state.twist = twist\r\n        req.state.reference_frame = \'world\'\r\n\r\n        return req\r\n\r\n    def create_get_state_request(self, entity_name: str, reference_frame: str):\r\n        """Create a GetEntityState request"""\r\n        from gazebo_msgs.srv import GetEntityState\r\n\r\n        req = GetEntityState.Request()\r\n        req.name = entity_name\r\n        req.reference_frame = reference_frame\r\n\r\n        return req\r\n\r\n    def set_robot_pose(self, pose: Pose):\r\n        """Set robot pose in Gazebo"""\r\n        req = self.create_set_state_request(self.robot_name, pose, Twist())\r\n\r\n        future = self.set_state_client.call_async(req)\r\n        # In a real implementation, you\'d handle the future response\r\n\r\n    def move_robot(self, linear_vel: float, angular_vel: float):\r\n        """Move robot in Gazebo with specified velocities"""\r\n        twist = Twist()\r\n        twist.linear.x = linear_vel\r\n        twist.angular.z = angular_vel\r\n\r\n        req = self.create_set_state_request(self.robot_name, self.current_pose, twist)\r\n\r\n        future = self.set_state_client.call_async(req)\r\n\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    node = GazeboIntegrationNode()\r\n\r\n    try:\r\n        rclpy.spin(node)\r\n    except KeyboardInterrupt:\r\n        node.get_logger().info(\'Gazebo integration node interrupted\')\r\n    finally:\r\n        node.destroy_node()\r\n        rclpy.shutdown()\r\n\r\n\r\nif __name__ == \'__main__\':\r\n    main()\n'})}),"\n",(0,s.jsx)(n.h2,{id:"isaac-integration-template",children:"Isaac Integration Template"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\r\n"""\r\nTemplate for NVIDIA Isaac integration\r\n"""\r\n\r\nimport rclpy\r\nfrom rclpy.node import Node\r\nfrom sensor_msgs.msg import Image, CameraInfo\r\nfrom geometry_msgs.msg import Twist\r\nfrom std_msgs.msg import String\r\nimport numpy as np\r\nimport cv2\r\nfrom cv_bridge import CvBridge\r\n\r\n\r\nclass IsaacIntegrationNode(Node):\r\n    def __init__(self):\r\n        super().__init__(\'isaac_integration\')\r\n\r\n        # Publishers for Isaac-related topics\r\n        self.perception_pub = self.create_publisher(String, \'isaac_perception_result\', 10)\r\n        self.control_cmd_pub = self.create_publisher(Twist, \'isaac_control_cmd\', 10)\r\n\r\n        # Subscribers for Isaac sensors\r\n        self.rgb_sub = self.create_subscription(\r\n            Image, \'isaac_camera/rgb\', self.rgb_callback, 10)\r\n        self.depth_sub = self.create_subscription(\r\n            Image, \'isaac_camera/depth\', self.depth_callback, 10)\r\n        self.camera_info_sub = self.create_subscription(\r\n            CameraInfo, \'isaac_camera/camera_info\', self.camera_info_callback, 10)\r\n\r\n        # Initialize tools\r\n        self.bridge = CvBridge()\r\n        self.camera_info = None\r\n\r\n        # Isaac processing components\r\n        self.perception_pipeline = self.initialize_perception_pipeline()\r\n\r\n        self.get_logger().info(\'Isaac integration node initialized\')\r\n\r\n    def rgb_callback(self, msg: Image):\r\n        """Process RGB camera data from Isaac"""\r\n        try:\r\n            cv_image = self.bridge.imgmsg_to_cv2(msg, "bgr8")\r\n\r\n            # Process with Isaac perception pipeline\r\n            results = self.process_with_isaac_pipeline(cv_image)\r\n\r\n            # Publish results\r\n            result_msg = String()\r\n            result_msg.data = str(results)\r\n            self.perception_pub.publish(result_msg)\r\n\r\n        except Exception as e:\r\n            self.get_logger().error(f\'Error processing RGB image: {e}\')\r\n\r\n    def depth_callback(self, msg: Image):\r\n        """Process depth data from Isaac"""\r\n        try:\r\n            cv_depth = self.bridge.imgmsg_to_cv2(msg, "32FC1")\r\n\r\n            # Process depth information\r\n            self.process_depth_data(cv_depth)\r\n\r\n        except Exception as e:\r\n            self.get_logger().error(f\'Error processing depth image: {e}\')\r\n\r\n    def camera_info_callback(self, msg: CameraInfo):\r\n        """Update camera information"""\r\n        self.camera_info = msg\r\n\r\n    def initialize_perception_pipeline(self):\r\n        """Initialize Isaac perception components"""\r\n        # In a real Isaac implementation, this would initialize\r\n        # Isaac-specific perception modules\r\n        return {\r\n            \'object_detection\': True,\r\n            \'pose_estimation\': True,\r\n            \'semantic_segmentation\': True\r\n        }\r\n\r\n    def process_with_isaac_pipeline(self, image: np.ndarray):\r\n        """Process image using Isaac perception pipeline"""\r\n        # This is a simplified representation\r\n        # In real Isaac, this would use Isaac\'s GPU-accelerated perception\r\n        results = {\r\n            \'objects_detected\': 0,\r\n            \'processing_time\': 0.0,\r\n            \'confidence\': 0.0\r\n        }\r\n\r\n        # Simple example: detect colored objects\r\n        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\r\n\r\n        # Red color range\r\n        lower_red = np.array([0, 50, 50])\r\n        upper_red = np.array([10, 255, 255])\r\n        mask = cv2.inRange(hsv, lower_red, upper_red)\r\n\r\n        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\r\n\r\n        results[\'objects_detected\'] = len([c for c in contours if cv2.contourArea(c) > 500])\r\n        results[\'processing_time\'] = 0.01  # Simulated processing time\r\n        results[\'confidence\'] = 0.8 if results[\'objects_detected\'] > 0 else 0.1\r\n\r\n        return results\r\n\r\n    def process_depth_data(self, depth_image: np.ndarray):\r\n        """Process depth information for 3D understanding"""\r\n        # In Isaac, this would use GPU-accelerated depth processing\r\n        if depth_image.size > 0:\r\n            # Calculate some statistics\r\n            valid_depths = depth_image[depth_image > 0]\r\n            if valid_depths.size > 0:\r\n                avg_depth = np.mean(valid_depths)\r\n                min_depth = np.min(valid_depths)\r\n                max_depth = np.max(valid_depths)\r\n\r\n                self.get_logger().debug(\r\n                    f\'Depth stats - Avg: {avg_depth:.2f}, Min: {min_depth:.2f}, Max: {max_depth:.2f}\'\r\n                )\r\n\r\n    def generate_control_command(self, perception_results: dict) -> Twist:\r\n        """Generate control commands based on perception results"""\r\n        cmd = Twist()\r\n\r\n        if perception_results.get(\'objects_detected\', 0) > 0:\r\n            # Move toward detected objects\r\n            cmd.linear.x = 0.2\r\n            cmd.angular.z = 0.0  # No turning for now\r\n        else:\r\n            # Stop if no objects detected\r\n            cmd.linear.x = 0.0\r\n            cmd.angular.z = 0.0\r\n\r\n        return cmd\r\n\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    node = IsaacIntegrationNode()\r\n\r\n    try:\r\n        rclpy.spin(node)\r\n    except KeyboardInterrupt:\r\n        node.get_logger().info(\'Isaac integration node interrupted\')\r\n    finally:\r\n        node.destroy_node()\r\n        rclpy.shutdown()\r\n\r\n\r\nif __name__ == \'__main__\':\r\n    main()\n'})}),"\n",(0,s.jsx)(n.h2,{id:"launch-file-template",children:"Launch File Template"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-xml",children:'<?xml version="1.0"?>\r\n<launch>\r\n  \x3c!-- Arguments --\x3e\r\n  <arg name="robot_name" default="my_humanoid_robot"/>\r\n  <arg name="use_sim_time" default="false"/>\r\n  <arg name="gui" default="true"/>\r\n\r\n  \x3c!-- Robot description parameter --\x3e\r\n  <param name="robot_description"\r\n         value="$(find-pkg-share my_robot_description)/urdf/my_robot.urdf"/>\r\n\r\n  \x3c!-- Use simulation time if needed --\x3e\r\n  <param name="use_sim_time" value="$(var use_sim_time)"/>\r\n\r\n  \x3c!-- Robot state publisher --\x3e\r\n  <node pkg="robot_state_publisher"\r\n        exec="robot_state_publisher"\r\n        name="robot_state_publisher">\r\n    <param name="robot_description" value="$(var robot_description)"/>\r\n  </node>\r\n\r\n  \x3c!-- Joint state publisher --\x3e\r\n  <node pkg="joint_state_publisher"\r\n        exec="joint_state_publisher"\r\n        name="joint_state_publisher">\r\n    <param name="use_gui" value="$(var gui)"/>\r\n  </node>\r\n\r\n  \x3c!-- Robot controllers --\x3e\r\n  <node pkg="my_robot_control"\r\n        exec="robot_control_node"\r\n        name="robot_controller">\r\n    <param name="max_velocity" value="1.0"/>\r\n    <param name="max_torque" value="50.0"/>\r\n  </node>\r\n\r\n  \x3c!-- Perception node --\x3e\r\n  <node pkg="my_robot_perception"\r\n        exec="perception_node"\r\n        name="perception_node">\r\n    <param name="confidence_threshold" value="0.7"/>\r\n    <param name="min_detection_area" value="500"/>\r\n  </node>\r\n\r\n  \x3c!-- TF broadcaster --\x3e\r\n  <node pkg="my_robot_bringup"\r\n        exec="tf_broadcaster"\r\n        name="tf_broadcaster"/>\r\n\r\n  \x3c!-- Load controller configurations --\x3e\r\n  <load_follower controller_manager_name="controller_manager"\r\n                 condition="$(eval use_sim_time == false)">\r\n    <controller name="joint_state_controller"\r\n                type="joint_state_controller/JointStateController"/>\r\n    <controller name="position_controller"\r\n                type="position_controllers/JointGroupPositionController">\r\n      <param name="joints" value="[joint1, joint2, joint3]"/>\r\n    </controller>\r\n  </load_follower>\r\n</launch>\n'})}),"\n",(0,s.jsx)(n.h2,{id:"cmakeliststxt-template",children:"CMakeLists.txt Template"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cmake",children:'cmake_minimum_required(VERSION 3.8)\r\nproject(my_robot_package)\r\n\r\nif(CMAKE_COMPILER_IS_GNUCXX OR CMAKE_CXX_COMPILER_ID MATCHES "Clang")\r\n  add_compile_options(-Wall -Wextra -Wpedantic)\r\nendif()\r\n\r\n# Find dependencies\r\nfind_package(ament_cmake REQUIRED)\r\nfind_package(rclcpp REQUIRED)\r\nfind_package(std_msgs REQUIRED)\r\nfind_package(sensor_msgs REQUIRED)\r\nfind_package(geometry_msgs REQUIRED)\r\nfind_package(visualization_msgs REQUIRED)\r\nfind_package(message_filters REQUIRED)\r\n\r\n# Install Python modules\r\nament_python_install_package(${PROJECT_NAME})\r\n\r\n# Install Python executables\r\ninstall(PROGRAMS\r\n  scripts/basic_robot_node.py\r\n  scripts/robot_control_node.py\r\n  scripts/perception_node.py\r\n  DESTINATION lib/${PROJECT_NAME}\r\n)\r\n\r\n# Install launch files\r\ninstall(DIRECTORY\r\n  launch/\r\n  DESTINATION share/${PROJECT_NAME}/launch\r\n)\r\n\r\n# Install config files\r\ninstall(DIRECTORY\r\n  config/\r\n  DESTINATION share/${PROJECT_NAME}/config\r\n)\r\n\r\n# Install URDF files\r\ninstall(DIRECTORY\r\n  urdf/\r\n  DESTINATION share/${PROJECT_NAME}/urdf\r\n)\r\n\r\nif(BUILD_TESTING)\r\n  find_package(ament_lint_auto REQUIRED)\r\n  ament_lint_auto_find_test_dependencies()\r\nendif()\r\n\r\nament_package()\n'})}),"\n",(0,s.jsx)(n.h2,{id:"packagexml-template",children:"package.xml Template"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-xml",children:'<?xml version="1.0"?>\r\n<?xml-model href="http://download.ros.org/schema/package_format3.xsd" schematypens="http://www.w3.org/2001/XMLSchema"?>\r\n<package format="3">\r\n  <name>my_robot_package</name>\r\n  <version>1.0.0</version>\r\n  <description>Package for my robot implementation following Physical AI & Humanoid Robotics textbook</description>\r\n  <maintainer email="maintainer@example.com">Maintainer Name</maintainer>\r\n  <license>Apache License 2.0</license>\r\n\r\n  <buildtool_depend>ament_cmake</buildtool_depend>\r\n  <buildtool_depend>ament_cmake_python</buildtool_depend>\r\n\r\n  <depend>rclcpp</depend>\r\n  <depend>rclpy</depend>\r\n  <depend>std_msgs</depend>\r\n  <depend>sensor_msgs</depend>\r\n  <depend>geometry_msgs</depend>\r\n  <depend>visualization_msgs</depend>\r\n  <depend>message_filters</depend>\r\n  <depend>cv_bridge</depend>\r\n  <depend>tf2</depend>\r\n  <depend>tf2_ros</depend>\r\n  <depend>robot_state_publisher</depend>\r\n  <depend>joint_state_publisher</depend>\r\n\r\n  <test_depend>ament_lint_auto</test_depend>\r\n  <test_depend>ament_lint_common</test_depend>\r\n\r\n  <export>\r\n    <build_type>ament_cmake</build_type>\r\n  </export>\r\n</package>\n'})}),"\n",(0,s.jsx)(n.h2,{id:"unit-test-template",children:"Unit Test Template"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\r\n"""\r\nUnit tests for robot components\r\n"""\r\n\r\nimport unittest\r\nimport rclpy\r\nfrom rclpy.node import Node\r\nfrom std_msgs.msg import String\r\nimport sys\r\nimport time\r\n\r\n\r\nclass TestRobotNode(Node):\r\n    def __init__(self):\r\n        super().__init__(\'test_robot_node\')\r\n        self.publisher = self.create_publisher(String, \'test_topic\', 10)\r\n        self.received_messages = []\r\n\r\n    def callback(self, msg):\r\n        self.received_messages.append(msg.data)\r\n\r\n\r\nclass TestRobotComponents(unittest.TestCase):\r\n    @classmethod\r\n    def setUpClass(cls):\r\n        rclpy.init()\r\n\r\n    @classmethod\r\n    def tearDownClass(cls):\r\n        rclpy.shutdown()\r\n\r\n    def setUp(self):\r\n        self.node = TestRobotNode()\r\n\r\n    def tearDown(self):\r\n        self.node.destroy_node()\r\n\r\n    def test_basic_functionality(self):\r\n        """Test basic node functionality"""\r\n        self.assertIsNotNone(self.node)\r\n        self.assertEqual(self.node.get_name(), \'test_robot_node\')\r\n\r\n    def test_publisher_exists(self):\r\n        """Test that publisher is created correctly"""\r\n        publishers = self.node.get_publishers_info_by_topic(\'test_topic\')\r\n        self.assertTrue(len(publishers) > 0)\r\n\r\n    def test_message_publishing(self):\r\n        """Test message publishing and receiving"""\r\n        # This is a simplified test - in practice, you\'d use a subscriber\r\n        # to verify messages are received correctly\r\n        msg = String()\r\n        msg.data = \'test message\'\r\n\r\n        # Publish message\r\n        self.node.publisher.publish(msg)\r\n\r\n        # Verify no errors occurred during publishing\r\n        self.assertTrue(True)  # Basic verification\r\n\r\n    def test_robot_control_parameters(self):\r\n        """Test robot control parameters"""\r\n        # Example test for control parameters\r\n        max_velocity = 1.0\r\n        max_torque = 100.0\r\n\r\n        # Test that parameters are within reasonable ranges\r\n        self.assertGreater(max_velocity, 0)\r\n        self.assertLess(max_velocity, 10.0)  # Reasonable limit\r\n        self.assertGreater(max_torque, 0)\r\n        self.assertLess(max_torque, 1000.0)  # Reasonable limit\r\n\r\n\r\ndef main():\r\n    unittest.main()\r\n\r\n\r\nif __name__ == \'__main__\':\r\n    main()\n'})}),"\n",(0,s.jsx)(n.p,{children:"These templates provide a solid foundation for developing Physical AI and Humanoid Robotics applications. Each template includes proper error handling, safety considerations, and follows ROS 2 best practices. Developers can use these as starting points and customize them for their specific applications."})]})}function d(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(p,{...e})}):p(e)}}}]);